{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Germen Sentiment Model\n",
    "\n",
    "ressources: \n",
    "https://sites.google.com/view/germeval2017-absa/data?authuser=0\n",
    "https://huggingface.co/oliverguhr/german-sentiment-bert\n",
    "\n",
    "The model uses the Googles Bert architecture and was trained on 1.834 million German-language samples. The training data contains texts from various domains like Twitter, Facebook and movie, app and hotel reviews. You can find more information about the dataset and the training process in the [paper]('http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.201.pdf').\n",
    "  \n",
    "  \n",
    "  \n",
    "If you are interested in code and data that was used to train this model please have a look at this repository and our paper. Here is a table of the F1 scores that his model achieves on following datasets. Since we trained this model on a newer version of the transformer library, the results are slightly better than reported in the paper.  \n",
    "  \n",
    "| Dataset                                                             \t| f1 score \t|\n",
    "|---------------------------------------------------------------------\t|----------\t|\n",
    "| [holidaycheck]('https://github.com/oliverguhr/german-sentiment')    \t| 0.9568   \t|\n",
    "| [scare]('https://www.romanklinger.de/scare/')                       \t| 0.9418   \t|\n",
    "| [filmstarts]('https://github.com/oliverguhr/german-sentiment')      \t| 0.9021   \t|\n",
    "| [PotTs]('https://www.aclweb.org/anthology/L16-1181/')               \t| 0.6780   \t|\n",
    "| [germeval]('https://sites.google.com/view/germeval2017-absa/home')  \t| 0.7536   \t|\n",
    "| [sb10k]('https://www.spinningbytes.com/resources/germansentiment/') \t| 0.7376   \t|\n",
    "| [emotions]('https://github.com/oliverguhr/german-sentiment')        \t| 0.9649   \t|\n",
    "| AVERAGE                                                             \t| 0.85     \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german-bert-sentiment.tar.gz unpack.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import tarfile\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,AutoConfig\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "class Model():\n",
    "    def __init__(self,model_path:str,s3_bucket=None,file_prefix=None):\n",
    "        #load model\n",
    "        self.model,self.tokenizer = self.from_pretrained(model_path,s3_bucket,file_prefix)\n",
    "        #helper functions\n",
    "        self.clean_chars = re.compile(r'[^A-Za-züöäÖÜÄß ]', re.MULTILINE)\n",
    "        self.clean_http_urls = re.compile(r'https*\\S+', re.MULTILINE)\n",
    "        self.clean_at_mentions = re.compile(r'@\\S+', re.MULTILINE)\n",
    "\n",
    "    def replace_numbers(self,text: str) -> str:\n",
    "        # replace numbers 0-9 to real strings\n",
    "        return text.replace(\"0\",\" null\").replace(\"1\",\" eins\").replace(\"2\",\" zwei\").replace(\"3\",\" drei\").replace(\"4\",\" vier\").replace(\"5\",\" fünf\").replace(\"6\",\" sechs\").replace(\"7\",\" sieben\").replace(\"8\",\" acht\").replace(\"9\",\" neun\")         \n",
    "\n",
    "    def clean_text(self,text: str)-> str:    \n",
    "        text = text.replace(\"\\n\", \" \")        \n",
    "        text = self.clean_http_urls.sub('',text)\n",
    "        text = self.clean_at_mentions.sub('',text)        \n",
    "        text = self.replace_numbers(text)                \n",
    "        text = self.clean_chars.sub('', text)                        \n",
    "        text = ' '.join(text.split()) \n",
    "        text = text.strip().lower()\n",
    "        return text\n",
    "    \n",
    "    def save_model(self,out_path:str,model_name='model'):\n",
    "        self.model.save_pretrained(out_path)\n",
    "        self.tokenizer.save_pretrained(out_path)\n",
    "        pack_model(out_path,model_name)\n",
    "\n",
    "    def load_model(self,model_path:str):\n",
    "        if os.path.isfile(f'{model_path}/pytorch_model.bin'):\n",
    "            model  = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "            config = AutoConfig.from_pretrained(f'{model_path}/config.json')\n",
    "        return model\n",
    "    \n",
    "    def load_model_from_s3(self,model_path:str,s3_bucket:str,file_prefix:str):\n",
    "        if model_path and s3_bucket and file_prefix:\n",
    "            obj = s3.get_object(Bucket=s3_bucket, Key=file_prefix)\n",
    "            bytestream = io.BytesIO(obj['Body'].read())\n",
    "            tar = tarfile.open(fileobj=bytestream, mode=\"r:gz\")\n",
    "            config= AutoConfig.from_pretrained(f'{model_path}/config.json')\n",
    "            for member in tar.getmembers():\n",
    "                if member.name.endswith(\".bin\"):\n",
    "                    f = tar.extractfile(member)\n",
    "                    state = torch.load(io.BytesIO(f.read()))\n",
    "                    model = AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path=None ,state_dict=state, config=config)\n",
    "            return model\n",
    "        else:\n",
    "            raise KeyError('No S3 Bucket and Key Prefix provided')\n",
    "    \n",
    "    def load_tokenizer(self,model_path:str):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        return tokenizer\n",
    "\n",
    "    def from_pretrained(self,model_path:str,s3_bucket:str,file_prefix:str):\n",
    "        if os.path.isfile(f'{model_path}/pytorch_model.bin'):\n",
    "            model = self.load_model(model_path)\n",
    "        else:\n",
    "            model = self.load_model_from_s3(model_path,s3_bucket,file_prefix)\n",
    "        tokenizer = self.load_tokenizer(model_path)\n",
    "        return model,tokenizer\n",
    "    \n",
    "    def predict_sentiment(self, texts: Union[List[str],str] )-> List[str]:\n",
    "        try:\n",
    "            if isinstance(texts,str):\n",
    "                texts = [texts]\n",
    "            texts = [self.clean_text(text) for text in texts]\n",
    "          # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "            input_ids = self.tokenizer.batch_encode_plus(texts,pad_to_max_length=True, add_special_tokens=True)\n",
    "            input_ids = torch.tensor(input_ids[\"input_ids\"])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = self.model(input_ids)    \n",
    "            print(logits[0])\n",
    "            label_ids = torch.argmax(logits[0], axis=1)\n",
    "\n",
    "            labels = [self.model.config.id2label[label_id] for label_id in label_ids.tolist()]\n",
    "            if len(labels) == 1:\n",
    "                return labels[0]\n",
    "            return labels\n",
    "        except Exception as e:\n",
    "            raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: ./model/pytorch_model.bin: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm  ./model/pytorch_model.bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('./model','philschmid-models','sentiment_classifier/german-bert-sentiment.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4624, -0.8481,  0.0963]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_sentiment('Der Aktienkurs für Puma ist sehr gut.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\r\n",
      "\r\n",
      "- `transformers` version: 2.10.0\r\n",
      "- Platform: macOS-10.15.3-x86_64-i386-64bit\r\n",
      "- Python version: 3.8.2\r\n",
      "- PyTorch version (GPU?): 1.5.0 (False)\r\n",
      "- Tensorflow version (GPU?): not installed (NA)\r\n",
      "- Using GPU in script?: <fill in>\r\n",
      "- Using distributed or parallel set-up in script?: <fill in>\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
